{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyONCat (ONCat API from Python)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### About\n",
    "\n",
    "ONCat is a metadata catalog built to store information about neutron experiment data at HFIR / SNS.  The contents of the catalog can be viewed at https://oncat.ornl.gov.\n",
    "\n",
    "An API is available to allow programmatic access to the metadata stored in the catalog.  Documentation for the API is at https://oncat.ornl.gov/build.\n",
    "\n",
    "This notebook outlines the usage of \"PyONCat\", a Python module built to make communicating with the API a little easier.\n",
    "\n",
    "<p><font color='green'>**(Questions / requests / feedback?  Please contact ONCat Support: oncat-support@ornl.gov.)**</font></p>\n",
    "\n",
    "### Installation\n",
    "\n",
    "The latest version of PyONCat should already be installed on https://jupyter.sns.gov as well as instrument / analysis machines, but if you are using a machine without it then it can be installed using `pip` as follows:\n",
    "\n",
    "```\n",
    "pip install https://oncat.ornl.gov/packages/pyoncat-1.0-py3-none-any.whl\n",
    "```\n",
    "\n",
    "### Notebook Prerequisite (Run This First!)\n",
    "\n",
    "We'd like to be able to time some of the things we do later on in this notebook, so let's define a \"stopwatch\" to help us with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry -- you don't need to understand exactly *how* this works right now.  Just make sure you\n",
    "# indent things properly when using it.\n",
    "\n",
    "import contextlib\n",
    "import datetime\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def stopwatch():\n",
    "    \"\"\"Wrap things in this context manager to time how long they take.\"\"\"\n",
    "    start = datetime.datetime.now()\n",
    "    print(\"Started at %s...\" % start)\n",
    "    yield\n",
    "    end = datetime.datetime.now()\n",
    "    print(\"Finished at %s!\" % end)\n",
    "    print(\"Total time = %s \" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example stopwatch usage.  Note that everything indented will be timed by the stopwatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "with stopwatch():\n",
    "    # These will be timed...\n",
    "    time.sleep(1)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ... and this will not.\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "### 1 - Initial Setup\n",
    "\n",
    "#### Main `ONCat` Object Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyoncat\n",
    "\n",
    "# This is a temporary \"client ID\" intended for use in this tutorial **only**.\n",
    "CLIENT_ID = \"c0686270-e983-4c71-bd0e-bfa47243a47f\"\n",
    "\n",
    "oncat = pyoncat.ONCat(\n",
    "    \"https://oncat.ornl.gov\",\n",
    "    client_id=CLIENT_ID,\n",
    "    flow=pyoncat.RESOURCE_OWNER_CREDENTIALS_FLOW,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting Users for their XCAMS / UCAMS Password\n",
    "\n",
    "<p><font color='grey'>*(Here we are assuming you want to use the username you used to log in to jupyter.sns.gov.)*</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "username = getpass.getuser()\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging in With the User's Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oncat.login(username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='grey'>*(Please contact ONCat Support if you would like to be issued permanent client credentials for your own work.  Note that is it possible to have clients that use passwordless \"machine-to-machine\" authentication.)*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Basic Facility / Instrument Information\n",
    "\n",
    "#### Printing the Names of the Facilities Supported by ONCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities = oncat.Facility.list()\n",
    "\n",
    "[facility.name for facility in facilities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the Names of the Instruments Support by ONCat for a Single Facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = oncat.Instrument.list(facility=\"SNS\")\n",
    "\n",
    "[instrument.name for instrument in instruments]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Experiment Information\n",
    "\n",
    "#### Retrieving All Experiments for an Instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = oncat.Experiment.list(facility=\"SNS\", instrument=\"NOM\")\n",
    "\n",
    "len(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most people will not be able to see the vast majority of the experiments that have been run on any given instrument, and only the experiments for which you are a team member (or experiments marked as \"calibration\") are experiments you should be able to see.  Instrument staff should obviously be able to see all experiments for their instrument.\n",
    "\n",
    "In general, experiment directories you have access to on the file system should also be available to you in ONCat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting All the Information We Have for a given Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a calibration experiment that everyone has access to.\n",
    "nom_cal_exp = oncat.Experiment.retrieve(\n",
    "    \"IPTS-19564\",\n",
    "    facility=\"SNS\",\n",
    "    instrument=\"NOM\"\n",
    ")\n",
    "\n",
    "nom_cal_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the object we got back was an `ONCatRepresentation`.  This is just a slightly more convenient wrapper around the information we got back from the API, which has a nested, \"dictionary of dictionaries\" structure.\n",
    "\n",
    "#### Accessing Fields Using Standard Python Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_cal_exp.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most convenient syntax but only top-level fields can be retireved this way.\n",
    "\n",
    "#### Accessing Fields Using \"Square-Bracket\" Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_cal_exp[\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Square-bracket syntax is more powerful since it also works for deeply-nested fields.  Use dot-delimited paths to \"drill down\" into the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_cal_exp[\"indexed.run_number.ranges\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only drill down into dictionaries -- not arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nom_cal_exp[\"members.name\"]\n",
    "except KeyError:\n",
    "    print(\"Could not drill down!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the team member names, we should access the array of `members`, and then access the `name` of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[member[\"name\"] for member in nom_cal_exp[\"members\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Datafile Information\n",
    "\n",
    "<p><font color=\"red\">NOTE: From now on we will be dealing with datafile entries, for which we often store *large* amounts of information in the catalog.  Therefore, to make sure that your scripts always run as quickly as they can, it is important to be mindful about accidentally asking for more than you need.\n",
    "    \n",
    "Also, bear in mind that ONCat is a shared resource.  If a large number of expensive calls are made simultaneously, this may negatively impact the performance of other clients using the API.\n",
    "\n",
    "Strategies to keep things as quick as possible are discussed in the following section.\n",
    "</font></p>\n",
    "\n",
    "#### Retrieving All Datafiles for an Experiment\n",
    "\n",
    "Let's get all the datafiles for calibration experiment we looked at previously, and time how long it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with stopwatch():\n",
    "    datafiles = oncat.Datafile.list(\n",
    "        facility=\"SNS\",\n",
    "        instrument=\"NOM\",\n",
    "        experiment=\"IPTS-19564\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With any luck that should have been quite quick.  Let's see how many datafiles were returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, not a lot of datafiles.  Let's up the ante a bit and ask for all the datafiles in a slightly larger calibration experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with stopwatch():\n",
    "    datafiles = oncat.Datafile.list(\n",
    "        facility=\"SNS\",\n",
    "        instrument=\"NOM\",\n",
    "        experiment=\"IPTS-21285\"\n",
    "    )\n",
    "\n",
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That probably took quite a bit a little longer.  But why?  It's not like that's a *huge* number of files...\n",
    "\n",
    "Well, let's see what a single datafile contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, quite a lot of stuff...  Returning all of that for thousands of datafiles means the database has to read a lot from disk and a lot of bytes have to be sent across the network.  Those are obviously bottlenecks.\n",
    "\n",
    "<p><font color=\"grey\">*(Note that there is so much stuff per file because our cataloging strategy when parsing raw datafiles is to ingest as much as we possibly can, within reason.  A rough rule of thumb is, \"if it's an array then we ignore it, else let's just go ahead and shove it in the catalog\".)*</font></p>\n",
    "\n",
    "We will explore how to speed things up a little later, but for now let's take a look at what we have.\n",
    "\n",
    "#### Accessing Information on Datafiles \n",
    "\n",
    "The datafile objects we get from the API can be accessed in much the same way as the experiment objects we looked at before, except different information is stored.\n",
    "\n",
    "Every datafile has a location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0].location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the instrument works in terms of \"runs\", then raw datafiles will have a corresponding run number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0][\"indexed.run_number\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store when the file was created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0].created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also keep track of when we cataloged the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0].ingested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the vast majority of the remaining info is nested inside the metadata field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Easily Seeing All Fields at a Glace\n",
    "\n",
    "With all that metadata it can be hard to find what you're looking for.\n",
    "\n",
    "Luckily, there is an easier way to see all the dot-delimited paths in a given datafile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0].nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and a way to print out only the paths *within* a given path, for example all paths under the \"sample\" node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0].nodes(\"metadata.entry.sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the dot-delimited paths can then be fed back in to the square-bracket syntax.  For example, the `speedrequest1` value from the DAS logs can be retrieved like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0][\"metadata.entry.daslogs.speedrequest1.average_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Improving Performance\n",
    "\n",
    "Now let's try to speed things up a bit by being more specific about what we ask for and using a few more of the options avaiable to us in the API.\n",
    "\n",
    "#### Filtering by Run Number\n",
    "\n",
    "If we happen to know the exact run(s) we're looking for ahead of time, then that would mean we could ask for less datafiles to be retrieved from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comma-seperated ranges are allowed.\n",
    "run_numbers = \"75400-75449,75500-75999\"\n",
    "\n",
    "with stopwatch():\n",
    "    datafiles = oncat.Datafile.list(\n",
    "        facility=\"SNS\",\n",
    "        instrument=\"NOM\",\n",
    "        ranges_q=\"indexed.run_number:\" + run_numbers,\n",
    "    )\n",
    "\n",
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully retrieving those 550 files was a lot quicker than retrieving the 1,926 we asked for earlier.\n",
    "\n",
    "#### Filtering by Fields Using \"Projections\"\n",
    "\n",
    "It is also possible to ask for a much smaller sub-set of information for each datafile, using something called a projection.\n",
    "\n",
    "A projection is just a list of the same kind of dot-delimeted paths we were working with previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection=[\n",
    "    \"indexed.run_number\",\n",
    "    \"metadata.entry.sample.identifier\",\n",
    "    \"metadata.entry.sample.name\",\n",
    "    \"metadata.entry.sample.chemical_formula\",\n",
    "    \"metadata.entry.sample.mass\",\n",
    "    \"metadata.entry.sample.container_name\",\n",
    "    \"metadata.entry.title\",\n",
    "    \"metadata.entry.proton_charge\",\n",
    "    \"location\",\n",
    "]\n",
    "\n",
    "with stopwatch():\n",
    "    datafiles = oncat.Datafile.list(\n",
    "        facility=\"SNS\",\n",
    "        instrument=\"NOM\",\n",
    "        experiment=\"IPTS-21285\",\n",
    "        projection=projection,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we asked for all datafiles in the larger calibration experiment, that should have been *much* quicker to run.\n",
    "\n",
    "You can see how the resulting datafile objects we got back are much smaller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use `pandas` to print out everything that was returned in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "pandas.DataFrame(\n",
    "    data=[[datafile[item] for item in projection] for datafile in datafiles],\n",
    "    columns=projection,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Raw/Processed Using \"Tags\"\n",
    "\n",
    "As of Feb 2019 we only catalog raw files, but soon we will be cataloging reduced/processed files.  At that point, queries like the ones above will start to return a mixture of both.\n",
    "\n",
    "To \"future-proof\" your queries, you might want to consider filtering by the `type/raw` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = oncat.Datafile.list(\n",
    "    facility=\"SNS\",\n",
    "    instrument=\"NOM\",\n",
    "    experiment=\"IPTS-21285\",\n",
    "    projection=projection,\n",
    "    tags=[\"type/raw\"],\n",
    ")\n",
    "\n",
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering By File Extension\n",
    "\n",
    "Furthermore, you may also want to filter by file extension.  This is best shown with examples from CG3, which is \"SPICE\" instrument that writes out both `.xml` and `.dat` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_datafiles = oncat.Datafile.list(\n",
    "    facility=\"HFIR\",\n",
    "    instrument=\"CG3\",\n",
    "    experiment=\"IPTS-17241\",\n",
    "    projection=[\"location\"],\n",
    "    tags=[\"type/raw\"],\n",
    "    exts=[\".xml\"]\n",
    ")\n",
    "\n",
    "len(xml_datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_datafiles = oncat.Datafile.list(\n",
    "    facility=\"HFIR\",\n",
    "    instrument=\"CG3\",\n",
    "    experiment=\"IPTS-17241\",\n",
    "    projection=[\"location\"],\n",
    "    tags=[\"type/raw\"],\n",
    "    exts=[\".dat\"]\n",
    ")\n",
    "\n",
    "len(dat_datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datafiles = oncat.Datafile.list(\n",
    "    facility=\"HFIR\",\n",
    "    instrument=\"CG3\",\n",
    "    experiment=\"IPTS-17241\",\n",
    "    projection=[\"location\"],\n",
    "    tags=[\"type/raw\"],\n",
    ")\n",
    "\n",
    "len(all_datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_datafiles) == len(xml_datafiles) + len(dat_datafiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-default at jnrk-sns-analysis",
   "language": "python",
   "name": "jnrk-sns-analysis-python3-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
